from fastapi import FastAPI, HTTPException

from llama_index.core import (
    VectorStoreIndex, SimpleDirectoryReader, ServiceContext, Settings, StorageContext, SimpleKeywordTableIndex
)
#from llama_index.llms.openai import OpenAI Removed OpenAI call
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.vector_stores.faiss import FaissVectorStore
from llama_index.core.indices.keyword_table import KeywordTableIndex
from llama_index.core.indices.composability import ComposableGraph
from llama_index.core.postprocessor import SimilarityPostprocessor
from pydantic import BaseModel

import uvicorn
import faiss

# Initialize FastAPI app
app = FastAPI()

# Load Documents Repository
filename_fn = lambda filename: {"file_name": filename}
documents = SimpleDirectoryReader("C:/Users/mirko.petracca/git/genai-automation-elastic-poc/documents", file_metadata=filename_fn,  filename_as_id=True, recursive=True).load_data()

#OpenAI Key for Embeddings
OPENAI_API_KEY = ""

# Configure LlamaIndex
#llm = OpenAI(model="gpt-4", temperature=0.0, api_key=OPENAI_API_KEY) 
Settings.llm = None #No LLM

Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-small", api_key=OPENAI_API_KEY)
#Settings.node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=20)
#Settings.num_output = 512
#Settings.context_window = 3900
# dimensions of text-embedding-3-small
Settings.context_window = 3900  # Ensures enough space for retrieval
Settings.num_output = 512  # Limits LlamaIndex's response generation
Settings.node_parser = None # Prevents automatic chunk expansion

# FAISS Index Storage
d = 1536  # Embedding dimension
faiss_index = faiss.IndexFlatL2(d)
vector_store = FaissVectorStore(faiss_index=faiss_index)
storage_context = StorageContext.from_defaults(vector_store=vector_store)

# Populate FAISS
vector_index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)

# Create BM25 Index (No LLM)
keyword_index = KeywordTableIndex.from_documents(documents, llm=None)

# âœ… Create Retrievers for BM25 and FAISS
bm25_retriever = keyword_index.as_retriever(similarity_top_k=5)  # âœ… BM25 Retriever
faiss_retriever = vector_index.as_retriever(similarity_top_k=5)  # âœ… FAISS Retriever

# âœ… Hybrid Retrieval Function
def hybrid_retrieve(query):
    bm25_results = bm25_retriever.retrieve(query)  # ðŸ”¹ Get BM25 results
    faiss_results = faiss_retriever.retrieve(query)  # ðŸ”¹ Get FAISS results

    # ðŸ”¹ Combine & Re-Rank
    combined_results = bm25_results + faiss_results
    
        # ðŸ”¹ Ensure scores are valid (Replace None with 0)
    for result in combined_results:
        if result.score is None:
            result.score = 0.0  # âœ… Replace None with 0
      
    #Filter out results with score == 0.0
    filtered_results = [r for r in combined_results if r.score > 0.0]
    ranked_results = sorted(filtered_results, key=lambda x: x.score, reverse=True)

    return ranked_results

class QueryRequest(BaseModel):
    query: str

@app.post("/query")
async def query_llama(request: QueryRequest):
    try:
        # Query LlamaIndex
        retriever = vector_index.as_retriever(similarity_top_k=10)
        response = retriever.retrieve(request.query)

        # Convert response to JSON
        results = [{"id": i, "filename": r.metadata.get("file_name", "Unknown"), "text": r.text} for i, r in enumerate(response)]
        return {"query": request.query, "results": results}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/queryHybrid")
async def query_llama(request: QueryRequest):
    try:
        response = hybrid_retrieve(request.query)  # âœ… Manually combine BM25 & FAISS

        # âœ… Fix: Iterate over response directly (No `.source_nodes`)
        results = [
            {"id": i, "filename": r.metadata.get("file_name", "Unknown").rpartition("\\")[2], "text": r.text, "score": r.score}
            for i, r in enumerate(response)
        ]
        return {"query": request.query, "results": results}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/refresh")
async def refreshIndex_llama():
    try:
        print("Refreshing Vector Index...")
        #index.refresh_ref_docs(documents)
        print(index.ref_doc_info)
        print("Vector Index Refreshed.")
        return {"ok"}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8001)